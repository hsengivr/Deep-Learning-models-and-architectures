{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOyl6NkgHvPNon6LsFexmrF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"F2m2zTtGJiZ6","executionInfo":{"status":"ok","timestamp":1707286184401,"user_tz":-330,"elapsed":1586,"user":{"displayName":"vignesh R","userId":"01030958218173470676"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","from torchsummary import summary"]},{"cell_type":"code","source":["class Stem(nn.Module):\n","  def __init__(self):\n","    super(Stem , self).__init__()\n","    self.conv1 = nn.Conv2d(in_channels= 3 , out_channels= 64 ,kernel_size=(7,7) , stride= (2,2) , padding=(3,3))\n","    self.conv2 = nn.Conv2d(in_channels= 64 , out_channels= 64 ,kernel_size=(1,1) , stride= (1,1), padding=0)\n","    self.conv3 = nn.Conv2d(in_channels= 64 , out_channels= 192 ,kernel_size=(3,3) , stride= (1,1), padding=(1,1))\n","    self.maxPool = nn.MaxPool2d(kernel_size=(3,3) , stride=(2,2) , padding=1)\n","\n","  def forward(self , x):\n","    out = self.conv1(x)\n","    out = F.relu(out)\n","\n","    out = self.maxPool(out)\n","\n","    out = self.conv2(out)\n","    out = F.relu(out)\n","\n","    out = self.conv3(out)\n","    out = F.relu(out)\n","\n","    out = self.maxPool(out)\n","\n","    return out"],"metadata":{"id":"7audVL3tKE6Q","executionInfo":{"status":"ok","timestamp":1707286184775,"user_tz":-330,"elapsed":377,"user":{"displayName":"vignesh R","userId":"01030958218173470676"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class InceptionBlock(nn.Module):\n","  def __init__(self , nbr_channels ,nbr_kernels):\n","    super(InceptionBlock , self).__init__()\n","    k_1 , k_2_1 , k_2_2 , k_3_1 , k_3_2 , k_4 = nbr_kernels\n","\n","    self.branch1 = nn.Sequential(\n","        nn.Conv2d(in_channels = nbr_channels , out_channels= k_1 , kernel_size=(1,1) , stride=(1,1)),\n","        nn.ReLU()\n","    )\n","\n","    self.branch2 = nn.Sequential(\n","        nn.Conv2d(in_channels= nbr_channels , out_channels= k_2_1 , kernel_size= (1,1), stride=(1,1)),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels= k_2_1 , out_channels= k_2_2 , kernel_size= (3,3) , stride=(1,1) , padding=(1,1)),\n","        nn.ReLU()\n","    )\n","\n","    self.branch3 = nn.Sequential(\n","        nn.Conv2d(in_channels= nbr_channels , out_channels= k_3_1 , kernel_size= (1,1) , stride=(1,1)),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels= k_3_1 , out_channels= k_3_2 , kernel_size= (5,5),  stride=(1,1) , padding = (2,2)),\n","        nn.ReLU()\n","    )\n","\n","    self.branch4 = nn.Sequential(\n","        nn.MaxPool2d(kernel_size=(3,3) , stride=(1,1) , padding=(1,1)),\n","        nn.Conv2d(in_channels= nbr_channels , out_channels= k_4 , kernel_size= (1,1), stride=(1,1)),\n","        nn.ReLU()\n","    )\n","\n","  def forward(self , x):\n","    out1 = self.branch1(x)\n","    out2 = self.branch2(x)\n","    out3 = self.branch3(x)\n","    out4 = self.branch4(x)\n","\n","    return torch.cat([out1 ,out2 , out3 , out4] , 1)\n"],"metadata":{"id":"Ci0TaqL5KFc7","executionInfo":{"status":"ok","timestamp":1707286184776,"user_tz":-330,"elapsed":8,"user":{"displayName":"vignesh R","userId":"01030958218173470676"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class GoogleNet(nn.Module):\n","  def __init__(self):\n","    super(GoogleNet , self).__init__()\n","\n","    # Output Size : 28*28*192\n","    self.stem = Stem()\n","\n","    # Output Size : 28*28*256\n","    self.Inception1_1 = InceptionBlock(192,[64 , 96 , 128 , 16 , 32 , 32])\n","\n","    # Output Size : 28*28*480\n","    self.Inception1_2 = InceptionBlock(256,[128 , 128 , 192 , 32 , 96 , 64])\n","\n","    # Output Size : 14*14*512\n","    self.Inception2 = InceptionBlock(480,[192 , 96 , 208 , 16 , 48 , 64])\n","\n","    # Output Size : 14*14*512\n","    self.Inception3_1 = InceptionBlock(512,[160 , 112 , 224 , 24 , 64 , 64])\n","    # Output Size : 14*14*512\n","    self.Inception3_2 = InceptionBlock(512,[128 , 128 , 256 , 24 , 64 , 64])\n","    # Output Size : 14*14*528\n","    self.Inception3_3 = InceptionBlock(512,[112 , 144 , 288 , 32 , 64 , 64])\n","\n","    # Output Size : 14*14*832\n","    self.Inception4 = InceptionBlock(528,[256 , 160 , 320 , 32 , 128 , 128])\n","\n","\n","    # Output Size : 7*7*832\n","    self.Inception5_1 = InceptionBlock(832,[256 , 160 , 320 , 32 , 128 , 128])\n","\n","    # Output Size : 7*7*1024\n","    self.Inception5_2 = InceptionBlock(832,[384 , 192 , 384 , 48 , 128 , 128])\n","\n","    self.maxPool = nn.MaxPool2d(kernel_size=(3,3) , stride=(2,2) , padding=1)\n","    self.avgPool = nn.AvgPool2d(kernel_size=(7,7) , stride=(1,1))\n","\n","    self.fc1 = nn.Linear(in_features=1024 , out_features =1000 )\n","    self.fc2 = nn.Linear(in_features=1000 , out_features =1000 )\n","\n","    self.auxiliary_classifier_1 = nn.Sequential(\n","        nn.AvgPool2d(kernel_size=(5,5) , stride=(3,3)),\n","        nn.Conv2d(in_channels=512 , out_channels=128 , kernel_size=(1,1) , stride=(1,1)),\n","        nn.ReLU(),\n","        nn.Linear(in_features = 4, out_features=1024),\n","        nn.ReLU(),\n","        nn.Linear(in_features=1024 , out_features=1000),\n","        nn.Softmax()\n","    )\n","\n","    self.auxiliary_classifier_2 = nn.Sequential(\n","        nn.AvgPool2d(kernel_size=(5,5) , stride=(3,3) , padding = (1,1)),\n","        nn.Conv2d(in_channels=528 , out_channels=128 , kernel_size=(1,1) , stride=(1,1)),\n","        nn.ReLU(),\n","        nn.Linear(in_features = 4, out_features=1024),\n","        nn.ReLU(),\n","        nn.Linear(in_features=1024 , out_features=1000),\n","        nn.Softmax()\n","    )\n","\n","  def forward(self , x):\n","\n","    out = self.stem(x)\n","\n","    out = self.Inception1_1(out)\n","    out = self.Inception1_2(out)\n","\n","    out = self.maxPool(out)\n","\n","    out = self.Inception2(out)\n","\n","    aux1 = self.auxiliary_classifier_1(out)\n","\n","    out = self.Inception3_1(out)\n","    out = self.Inception3_2(out)\n","    out = self.Inception3_3(out)\n","\n","    aux2 = self.auxiliary_classifier_2(out)\n","\n","    out = self.Inception4(out)\n","\n","    out = self.maxPool(out)\n","\n","    out = self.Inception5_1(out)\n","    out = self.Inception5_2(out)\n","\n","    out = self.avgPool(out)\n","\n","    out = out.reshape(out.shape[0] , -1)\n","\n","    out = self.fc1(out)\n","    out = F.relu(out)\n","    out = nn.Dropout(p=0.4)(out)\n","    out = self.fc2(out)\n","    out = F.softmax(out)\n","\n","    return out\n"],"metadata":{"id":"dF92gPYKKI4N","executionInfo":{"status":"ok","timestamp":1707286184776,"user_tz":-330,"elapsed":6,"user":{"displayName":"vignesh R","userId":"01030958218173470676"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model = GoogleNet()\n","summary(model , (3 , 224 , 224))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dnHZ3dS6KNsL","executionInfo":{"status":"ok","timestamp":1707286185523,"user_tz":-330,"elapsed":752,"user":{"displayName":"vignesh R","userId":"01030958218173470676"}},"outputId":"cc86ce26-d7c0-4eaa-b9b5-bbf9208716c4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self._call_impl(*args, **kwargs)\n","<ipython-input-4-b6f3504e06cd>:94: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  out = F.softmax(out)\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,472\n","         MaxPool2d-2           [-1, 64, 56, 56]               0\n","            Conv2d-3           [-1, 64, 56, 56]           4,160\n","            Conv2d-4          [-1, 192, 56, 56]         110,784\n","         MaxPool2d-5          [-1, 192, 28, 28]               0\n","              Stem-6          [-1, 192, 28, 28]               0\n","            Conv2d-7           [-1, 64, 28, 28]          12,352\n","              ReLU-8           [-1, 64, 28, 28]               0\n","            Conv2d-9           [-1, 96, 28, 28]          18,528\n","             ReLU-10           [-1, 96, 28, 28]               0\n","           Conv2d-11          [-1, 128, 28, 28]         110,720\n","             ReLU-12          [-1, 128, 28, 28]               0\n","           Conv2d-13           [-1, 16, 28, 28]           3,088\n","             ReLU-14           [-1, 16, 28, 28]               0\n","           Conv2d-15           [-1, 32, 28, 28]          12,832\n","             ReLU-16           [-1, 32, 28, 28]               0\n","        MaxPool2d-17          [-1, 192, 28, 28]               0\n","           Conv2d-18           [-1, 32, 28, 28]           6,176\n","             ReLU-19           [-1, 32, 28, 28]               0\n","   InceptionBlock-20          [-1, 256, 28, 28]               0\n","           Conv2d-21          [-1, 128, 28, 28]          32,896\n","             ReLU-22          [-1, 128, 28, 28]               0\n","           Conv2d-23          [-1, 128, 28, 28]          32,896\n","             ReLU-24          [-1, 128, 28, 28]               0\n","           Conv2d-25          [-1, 192, 28, 28]         221,376\n","             ReLU-26          [-1, 192, 28, 28]               0\n","           Conv2d-27           [-1, 32, 28, 28]           8,224\n","             ReLU-28           [-1, 32, 28, 28]               0\n","           Conv2d-29           [-1, 96, 28, 28]          76,896\n","             ReLU-30           [-1, 96, 28, 28]               0\n","        MaxPool2d-31          [-1, 256, 28, 28]               0\n","           Conv2d-32           [-1, 64, 28, 28]          16,448\n","             ReLU-33           [-1, 64, 28, 28]               0\n","   InceptionBlock-34          [-1, 480, 28, 28]               0\n","        MaxPool2d-35          [-1, 480, 14, 14]               0\n","           Conv2d-36          [-1, 192, 14, 14]          92,352\n","             ReLU-37          [-1, 192, 14, 14]               0\n","           Conv2d-38           [-1, 96, 14, 14]          46,176\n","             ReLU-39           [-1, 96, 14, 14]               0\n","           Conv2d-40          [-1, 208, 14, 14]         179,920\n","             ReLU-41          [-1, 208, 14, 14]               0\n","           Conv2d-42           [-1, 16, 14, 14]           7,696\n","             ReLU-43           [-1, 16, 14, 14]               0\n","           Conv2d-44           [-1, 48, 14, 14]          19,248\n","             ReLU-45           [-1, 48, 14, 14]               0\n","        MaxPool2d-46          [-1, 480, 14, 14]               0\n","           Conv2d-47           [-1, 64, 14, 14]          30,784\n","             ReLU-48           [-1, 64, 14, 14]               0\n","   InceptionBlock-49          [-1, 512, 14, 14]               0\n","        AvgPool2d-50            [-1, 512, 4, 4]               0\n","           Conv2d-51            [-1, 128, 4, 4]          65,664\n","             ReLU-52            [-1, 128, 4, 4]               0\n","           Linear-53         [-1, 128, 4, 1024]           5,120\n","             ReLU-54         [-1, 128, 4, 1024]               0\n","           Linear-55         [-1, 128, 4, 1000]       1,025,000\n","          Softmax-56         [-1, 128, 4, 1000]               0\n","           Conv2d-57          [-1, 160, 14, 14]          82,080\n","             ReLU-58          [-1, 160, 14, 14]               0\n","           Conv2d-59          [-1, 112, 14, 14]          57,456\n","             ReLU-60          [-1, 112, 14, 14]               0\n","           Conv2d-61          [-1, 224, 14, 14]         226,016\n","             ReLU-62          [-1, 224, 14, 14]               0\n","           Conv2d-63           [-1, 24, 14, 14]          12,312\n","             ReLU-64           [-1, 24, 14, 14]               0\n","           Conv2d-65           [-1, 64, 14, 14]          38,464\n","             ReLU-66           [-1, 64, 14, 14]               0\n","        MaxPool2d-67          [-1, 512, 14, 14]               0\n","           Conv2d-68           [-1, 64, 14, 14]          32,832\n","             ReLU-69           [-1, 64, 14, 14]               0\n","   InceptionBlock-70          [-1, 512, 14, 14]               0\n","           Conv2d-71          [-1, 128, 14, 14]          65,664\n","             ReLU-72          [-1, 128, 14, 14]               0\n","           Conv2d-73          [-1, 128, 14, 14]          65,664\n","             ReLU-74          [-1, 128, 14, 14]               0\n","           Conv2d-75          [-1, 256, 14, 14]         295,168\n","             ReLU-76          [-1, 256, 14, 14]               0\n","           Conv2d-77           [-1, 24, 14, 14]          12,312\n","             ReLU-78           [-1, 24, 14, 14]               0\n","           Conv2d-79           [-1, 64, 14, 14]          38,464\n","             ReLU-80           [-1, 64, 14, 14]               0\n","        MaxPool2d-81          [-1, 512, 14, 14]               0\n","           Conv2d-82           [-1, 64, 14, 14]          32,832\n","             ReLU-83           [-1, 64, 14, 14]               0\n","   InceptionBlock-84          [-1, 512, 14, 14]               0\n","           Conv2d-85          [-1, 112, 14, 14]          57,456\n","             ReLU-86          [-1, 112, 14, 14]               0\n","           Conv2d-87          [-1, 144, 14, 14]          73,872\n","             ReLU-88          [-1, 144, 14, 14]               0\n","           Conv2d-89          [-1, 288, 14, 14]         373,536\n","             ReLU-90          [-1, 288, 14, 14]               0\n","           Conv2d-91           [-1, 32, 14, 14]          16,416\n","             ReLU-92           [-1, 32, 14, 14]               0\n","           Conv2d-93           [-1, 64, 14, 14]          51,264\n","             ReLU-94           [-1, 64, 14, 14]               0\n","        MaxPool2d-95          [-1, 512, 14, 14]               0\n","           Conv2d-96           [-1, 64, 14, 14]          32,832\n","             ReLU-97           [-1, 64, 14, 14]               0\n","   InceptionBlock-98          [-1, 528, 14, 14]               0\n","        AvgPool2d-99            [-1, 528, 4, 4]               0\n","          Conv2d-100            [-1, 128, 4, 4]          67,712\n","            ReLU-101            [-1, 128, 4, 4]               0\n","          Linear-102         [-1, 128, 4, 1024]           5,120\n","            ReLU-103         [-1, 128, 4, 1024]               0\n","          Linear-104         [-1, 128, 4, 1000]       1,025,000\n","         Softmax-105         [-1, 128, 4, 1000]               0\n","          Conv2d-106          [-1, 256, 14, 14]         135,424\n","            ReLU-107          [-1, 256, 14, 14]               0\n","          Conv2d-108          [-1, 160, 14, 14]          84,640\n","            ReLU-109          [-1, 160, 14, 14]               0\n","          Conv2d-110          [-1, 320, 14, 14]         461,120\n","            ReLU-111          [-1, 320, 14, 14]               0\n","          Conv2d-112           [-1, 32, 14, 14]          16,928\n","            ReLU-113           [-1, 32, 14, 14]               0\n","          Conv2d-114          [-1, 128, 14, 14]         102,528\n","            ReLU-115          [-1, 128, 14, 14]               0\n","       MaxPool2d-116          [-1, 528, 14, 14]               0\n","          Conv2d-117          [-1, 128, 14, 14]          67,712\n","            ReLU-118          [-1, 128, 14, 14]               0\n","  InceptionBlock-119          [-1, 832, 14, 14]               0\n","       MaxPool2d-120            [-1, 832, 7, 7]               0\n","          Conv2d-121            [-1, 256, 7, 7]         213,248\n","            ReLU-122            [-1, 256, 7, 7]               0\n","          Conv2d-123            [-1, 160, 7, 7]         133,280\n","            ReLU-124            [-1, 160, 7, 7]               0\n","          Conv2d-125            [-1, 320, 7, 7]         461,120\n","            ReLU-126            [-1, 320, 7, 7]               0\n","          Conv2d-127             [-1, 32, 7, 7]          26,656\n","            ReLU-128             [-1, 32, 7, 7]               0\n","          Conv2d-129            [-1, 128, 7, 7]         102,528\n","            ReLU-130            [-1, 128, 7, 7]               0\n","       MaxPool2d-131            [-1, 832, 7, 7]               0\n","          Conv2d-132            [-1, 128, 7, 7]         106,624\n","            ReLU-133            [-1, 128, 7, 7]               0\n","  InceptionBlock-134            [-1, 832, 7, 7]               0\n","          Conv2d-135            [-1, 384, 7, 7]         319,872\n","            ReLU-136            [-1, 384, 7, 7]               0\n","          Conv2d-137            [-1, 192, 7, 7]         159,936\n","            ReLU-138            [-1, 192, 7, 7]               0\n","          Conv2d-139            [-1, 384, 7, 7]         663,936\n","            ReLU-140            [-1, 384, 7, 7]               0\n","          Conv2d-141             [-1, 48, 7, 7]          39,984\n","            ReLU-142             [-1, 48, 7, 7]               0\n","          Conv2d-143            [-1, 128, 7, 7]         153,728\n","            ReLU-144            [-1, 128, 7, 7]               0\n","       MaxPool2d-145            [-1, 832, 7, 7]               0\n","          Conv2d-146            [-1, 128, 7, 7]         106,624\n","            ReLU-147            [-1, 128, 7, 7]               0\n","  InceptionBlock-148           [-1, 1024, 7, 7]               0\n","       AvgPool2d-149           [-1, 1024, 1, 1]               0\n","          Linear-150                 [-1, 1000]       1,025,000\n","          Linear-151                 [-1, 1000]       1,001,000\n","================================================================\n","Total params: 10,193,168\n","Trainable params: 10,193,168\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 90.20\n","Params size (MB): 38.88\n","Estimated Total Size (MB): 129.66\n","----------------------------------------------------------------\n"]}]}]}